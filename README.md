# ü§ñ Data Science Coding Challenge -> Therapy Chatbot Fine-Tuning

## Research
Before augmenting the psychology data for the Fine Tuning, it was crucial to conduct a research on relevant papers and studies about the use and application of Therapy chatbots. This involved exploring the implications in mental health, forming hypotheses, considering ethical implications, and addressing problems that may arise. Fine-tuning large language models has inherent risks, especially for text generation and assisting technologies. As the LLMs could be trained on datasets including scraped websites with harmful and banned content, so the responses to prompts can contain toxic language. Another ethical aspect that must be considered when developing a psychological bot is who is responsible for the bot‚Äôs actions.

One of the key papers that informed our research is:
- Author(s): Lindgren, Helena and Sj√∂str√∂m, Jonas
- Title: Fine-tuning a Language Model using Reinforcement Learning from Human Feedback for a Therapy Chatbot Application
- URL: [Link to the paper](https://www.diva-portal.org/smash/get/diva2:1782678/FULLTEXT01.pdf)

## Database
Based on the research, it was decided to fine-tune the model with data from papers and studies that can demonstrate not just a technical improvement of the loss and accuracy, but also a well-being for the patient. This involved fine-tuning a LLM using Reinforcement Learning from Human Feedback for a Therapy Chatbot Application. The dataset used for this investigation was a set of questions and answers from Counsel Chat. Counsel Chat is a platform where users can contact verified therapists and ask mental health-related questions.

## Code

## Results

## Performance
