# Data Science Coding Challenge - Therapy Chatbot Fine-Tuning

## Research
Before augmenting the psychology data for the Fine Tuning, it was crucial to conduct thorough research on relevant papers and studies about the use and application of Therapy chatbots. This involved exploring the implications in mental health, forming hypotheses, considering ethical implications, and addressing problems that may arise. Fine-tuning large language models has inherent risks, especially for text generation and assisting technologies. As the models are trained on datasets scraped from sites on the internet, including banned ones with harmful content, the responses to prompts can contain toxic language. Another ethical aspect that must be considered when developing a psychological bot is who is responsible for the botâ€™s actions.

## Database
Based on the research, it was decided to fine-tune the model with data from papers and studies that can demonstrate not just a technical improvement of the loss and accuracy, but also a well-being for the patient. This involved fine-tuning a LLM using Reinforcement Learning from Human Feedback for a Therapy Chatbot Application. The dataset used for this investigation was a set of questions and answers from Counsel Chat. Counsel Chat is a platform where users can contact verified therapists and ask mental health-related questions.

## Code

## Results

## Performance
